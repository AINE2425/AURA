{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "clusters = [\n",
        "# Applications of RPA in the healthcare industry\n",
        "  [\n",
        "    \"With the advent of Technology in the healthcare industry, there is a growth in revenue generation. Patients, doctors, insurance companies, and other entities are the key players in Healthcare Industry. Further effective and accurate back workplace method is urgently needed towards maintaining poise among the growing number of patients and the paperwork required for development plus insurance prerogatives, among other things. Hence, this concerns progressive mechanisation elucidations such as Robotic Process Automation (RPA) being able to assist healthcare organisations in increasing effective proficiency, lowering expenses, and reducing the risk of human error once handling data such as doctor credentialing, staffing, and patient fitness, as well as medical record maintenance, payables and denial recover, and patient scheduling.\",\n",
        "    \"Robotic process automation (RPA) is transforming the healthcare industry through the automation of jobs, optimisation of workflows, and improvement of operational efficiency. This chapter examines the revolutionary capacity of robotic process automation (RPA), emphasising its various uses, advantages, and ethical implications. Although RPA enhances the efficiency of resource allocation and enhances the quality of patient care, it is crucial to tackle concerns such as job displacement and data privacy. Empirical case studies provide concrete evidence of the tangible effects of robotic process automation (RPA) on the delivery of healthcare services. Anticipating and adopting the progress of robotic process automation (RPA) with ethical accountability holds the potential for a more streamlined and patient-focused healthcare system.\",\n",
        "    \"An emerging technology breakthrough called robotic process automation (RPA) is being designed to alleviate users’ everyday responsibilities of tedious and monotonous operations. This technology presents the fraternity of researchers with a brand-new field of study, and several research investigations are now being conducted in this area. It isn’t robotics; rather, it represents completely distinct area of technology. Robotic process automation is a new as well as rapidly expanding area of robotic systems. This study highlights the significant features of robotic process automation (RPA) and its application in healthcare industry.\"\n",
        "  ],\n",
        "# UI element detection\n",
        "  [\n",
        "    \"Robotic Process Mining (RPM) leverages User Interface (UI) logs as a source of information to analyze the processes to be automated. These UI logs record user interactions with the graphical user interface of an information system during the execution of a process, encapsulating a large amount of data. However, despite the abundance of information captured in these logs, a considerable portion remains on the screen, whose structure is often inaccessible programmatically. This unstructured data poses a significant challenge, particularly the gap in the automatic extraction of UI hierarchies from desktop screenshots, which hinders the application of mining techniques. To address this challenge, this paper presents (1) an approach that employs a multi-model detection system designed specifically for different levels of UI abstraction and (2) an algorithm to reconstruct the UI hierarchy in a tree data structure. The results of this approach demonstrate higher performance in terms of accuracy, recall, and efficiency compared to other existing detection techniques. These findings represent a substantial contribution to the field of automated process analysis, providing a solid foundation for future advances in RPA analysis.\",\n",
        "    \"Transforming a graphical user interface screenshot created by a designer into computer code is a typical task conducted by a developer in order to build customized software, websites, and mobile applications. In this paper, we show that deep learning methods can be leveraged to train a model end-to-end to automatically reverse engineer user interfaces and generate code from a single input image with over 77% of accuracy for three different platforms (i.e. iOS, Android and web-based technologies).\",\n",
        "    \"Detecting Graphical User Interface (GUI) elements in GUI images is a domain-specific object detection task. It supports many software engineering tasks, such as GUI animation and testing, GUI search and code generation. Existing studies for GUI element detection directly borrow the mature methods from computer vision (CV) domain, including old fashioned ones that rely on traditional image processing features (e.g., canny edge, contours), and deep learning models that learn to detect from large-scale GUI data. Unfortunately, these CV methods are not originally designed with the awareness of the unique characteristics of GUIs and GUI elements and the high localization accuracy of the GUI element detection task. We conduct the first large-scale empirical study of seven representative GUI element detection methods on over 50k GUI images to understand the capabilities, limitations and effective designs of these methods. This study not only sheds the light on the technical challenges to be addressed but also informs the design of new GUI element detection methods. We accordingly design a new GUI-specific old-fashioned method for non-text GUI element detection which adopts a novel top-down coarse-to-fine strategy, and incorporate it with the mature deep learning model for GUI text detection.Our evaluation on 25,000 GUI images shows that our method significantly advances the start-of-the-art performance in GUI element detection.\"\n",
        "  ],\n",
        "# Quantum Recommender systems\n",
        " [\n",
        "    \"In the context of recommendation systems, there have been recent developments which propose quantum computing to improve both efficacy and efficiency in terms of time. Within this context, the existing problem of measuring and comparing the electric efficiency of both systems is key to understanding the benefits and disadvantages quantum solutions could provide within the recommendation systems realm.This is a problem because existing solutions only consider effectiveness and efficiency in terms of time taken to resolve recommendations, leaving aside the electrical consumption. To address this gap, we propose a comparison of traditional and quantum solutions to recommender systems, which would allow us to measure whether there is a significant difference between these types of solutions in terms of electricity consumption while maintaining effectiveness. This solution would be the first to quantitatively measure such differences, providing valuable insights into the potential application of quantum computing in real-world recommendation systems.\",\n",
        "    \"The rising demand for high-quality movie recommendations in streaming services necessitates more efficient algorithms capable of handling large datasets. Traditional recommendation systems often struggle with long training times and high computational costs. This study introduces a novel movie recommendation system utilizing a quantum support vector machine (QSVM) to overcome these limitations. By leveraging quantum algorithms, QSVM enhances both the speed and accuracy of recommendations. Our approach involves collecting and preprocessing data, implementing classical SVM for baseline comparison, encoding data for QSVM, and executing QSVM using a publicly accessible IBM quantum computer. The results demonstrate that QSVM outperforms classical SVM, achieving a 96% accuracy and an F1 score of 0.9693, compared to the classical SVM’s 95.33% accuracy and 0.9641 F1 score. This signifies QSVM’s superior capability in handling complex datasets. Our findings highlight the potential of QSVM in movie recommendation systems, suggesting future research directions in quantum machine learning and its applications.\",\n",
        "    \"Recommender systems are crucial in delivering personalized content and enhancing user satisfaction. This paper investigates the performance of various machine learning algorithms, classical neural networks (CNNs), and quantum neural networks (QNNs) for movie recommendations using the MovieLens-1 M dataset. Traditional approaches like random forest, K-means, and support vector machines (SVM) are evaluated against the newly proposed QNN models. Two distinct QNN architectures are introduced, leveraging the principles of quantum computing, such as superposition and entanglement, to enhance recommendation accuracy. The study demonstrates that the simple QNN architecture significantly outperforms traditional machine learning models and CNNs, reducing prediction errors by 6% in terms of Mean Absolute Error (MAE) and Root Mean Square Error (RMSE). The complex QNN model, while accurate, requires more computational resources compared to its simpler counterpart. This research highlights the transformative potential of quantum computing in recommender systems, offering unprecedented accuracy and personalization. Future research will focus on scalability, practical implementation of QNNs, and exploring their application across diverse domains.\"\n",
        "  ]\n",
        "]\n"
      ],
      "metadata": {
        "id": "RR7MhmXXdPmF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El plan es el siguiente. Hay dos fases. La segunda tiene dos opciones:\n",
        "1. TF-IDF para encontrar los terminos mas diferenciadores en cada cluster, asi como que terminos de otros clusters difieren mas de este. Una vez eso esta hecho, resumenes predefinidos pueden hacerse sin mucho esfuerzo, aunque no son muy determinados.\n",
        "2. Si el usuario ve un cluster interesante, puede decidir que quiere saber mas sobre los contenidos del mismo, haciendo un resumen general. Para esto se necesitaran modelos de lenguaje, que pueden ser LM o LLM. Aqui el problema es como se expone la diferencia con otros clusters. Se podrian dar los terminos con mas peso junto al resto de info por ejemplo."
      ],
      "metadata": {
        "id": "A0BN4SNMfnqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF summarization approach"
      ],
      "metadata": {
        "id": "0FmktYDB9FzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNGn9zw3rYTL",
        "outputId": "6bb4a3b4-4423-4026-9da0-1ae3ad9062ec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "metadata": {
        "id": "YGPcJVcnWvB8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "docs = [\n",
        "    list(\n",
        "      tqdm(     # Decoramos con tqdm para ver barra de progreso\n",
        "        nlp.pipe(cluster, n_process=-1),\n",
        "        total=len(cluster)\n",
        "        )\n",
        "    )\n",
        "    for cluster in clusters\n",
        "    ]"
      ],
      "metadata": {
        "id": "aOo8UyKbp8Br",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63ac085-82c3-410d-c6e9-f7601224af9b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  4.73it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 10.31it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00,  7.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Phrases\n",
        "from gensim.models.phrases import Phraser\n",
        "import pandas as pd\n",
        "\n",
        "# We will want to detect phrases such as \"neural_network\" to better identify clusters\n",
        "def detect_phrases(tokenized_docs: List[List[str]], min_count: int = 5, threshold: float = 10.0) -> List[List[str]]:\n",
        "    phrases = Phrases(tokenized_docs, min_count=min_count, threshold=threshold)\n",
        "    phraser = Phraser(phrases)\n",
        "    return [phraser[doc] for doc in tokenized_docs]\n",
        "\n",
        "tokenized_docs_per_cluster: List[List[List[str]]] = []\n",
        "\n",
        "# We lowercase everything to improve consistancy and differentiation.\n",
        "# We also convert to tokens before applying the detection of phrases\n",
        "for cluster_docs in docs:\n",
        "    cluster_tokens: List[List[str]] = []\n",
        "    for doc in cluster_docs:\n",
        "        lemmas = [token.lemma_.lower() for token in doc if token.is_alpha and not token.is_stop]\n",
        "        cluster_tokens.append(lemmas)\n",
        "    tokenized_docs_per_cluster.append(cluster_tokens)\n",
        "\n",
        "all_tokenized_docs: List[List[str]] = [lemma for cluster in tokenized_docs_per_cluster for lemma in cluster]\n",
        "all_tokenized_docs_with_phrases: List[List[str]] = detect_phrases(all_tokenized_docs)\n",
        "\n",
        "index = 0\n",
        "preprocessed_docs: List[str] = []\n",
        "\n",
        "# We merge the tokens into Strings to apply TF-IDF\n",
        "for cluster in tokenized_docs_per_cluster:\n",
        "    cluster_text_tokens: List[str] = []\n",
        "    for _ in cluster:\n",
        "        cluster_text_tokens.extend(all_tokenized_docs_with_phrases[index])\n",
        "        index += 1\n",
        "    preprocessed_docs.append(\" \".join(cluster_text_tokens))\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(), preprocessor=lambda x: x)\n",
        "tfidf_matrix = vectorizer.fit_transform(preprocessed_docs)\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "cluster_keywords: List[pd.DataFrame] = []\n",
        "\n",
        "for i in range(tfidf_matrix.shape[0]):\n",
        "    tfidf_scores = pd.DataFrame({\n",
        "        'word': feature_names,\n",
        "        'tfidf': tfidf_matrix[i].toarray()[0]\n",
        "    })\n",
        "    tfidf_scores = tfidf_scores.sort_values(by='tfidf', ascending=False)\n",
        "    cluster_keywords.append(tfidf_scores)\n",
        "\n",
        "for i in range(len(clusters)):\n",
        "    print(\"======================================================================\")\n",
        "    print(f\"Cluster {i + 1}:\")\n",
        "    print(\"Positive (appear more in this cluster):\")\n",
        "    print(cluster_keywords[i].head(5))\n",
        "    print(\"\\n\")\n",
        "    for j in range(len(clusters)):\n",
        "        if i != j:\n",
        "            print(f\"Negative against Cluster {j + 1}: (appear less in this cluster):\")\n",
        "            diff = cluster_keywords[i].merge(cluster_keywords[j], on='word', how='left').fillna(0)\n",
        "            diff['diff'] = diff['tfidf_x'] - diff['tfidf_y']\n",
        "            diff = diff.sort_values('diff', ascending=True)\n",
        "            print(diff.head(5))\n",
        "            print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1KEew0prvMs",
        "outputId": "ca6fb8ab-96cb-457f-f4e2-307e57e37d8c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Cluster 1:\n",
            "Positive (appear more in this cluster):\n",
            "                word     tfidf\n",
            "35    automation_rpa  0.375625\n",
            "168       healthcare  0.375625\n",
            "321  robotic_process  0.326483\n",
            "256          patient  0.321964\n",
            "186         industry  0.214643\n",
            "\n",
            "\n",
            "Negative against Cluster 2: (appear less in this cluster):\n",
            "            word  tfidf_x   tfidf_y      diff\n",
            "278    detection      0.0  0.375001 -0.375001\n",
            "399          gui      0.0  0.337500 -0.337500\n",
            "398  gui_element      0.0  0.300000 -0.300000\n",
            "341    interface      0.0  0.187500 -0.187500\n",
            "393        image      0.0  0.187500 -0.187500\n",
            "\n",
            "\n",
            "Negative against Cluster 3: (appear less in this cluster):\n",
            "               word  tfidf_x   tfidf_y      diff\n",
            "171         quantum      0.0  0.391482 -0.391482\n",
            "220  recommendation      0.0  0.391482 -0.391482\n",
            "136            qsvm      0.0  0.249125 -0.249125\n",
            "147             qnn      0.0  0.177946 -0.177946\n",
            "362         machine      0.0  0.177946 -0.177946\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Cluster 2:\n",
            "Positive (appear more in this cluster):\n",
            "            word     tfidf\n",
            "98     detection  0.375001\n",
            "165          gui  0.337500\n",
            "166  gui_element  0.300000\n",
            "225       method  0.228158\n",
            "386           ui  0.187500\n",
            "\n",
            "\n",
            "Negative against Cluster 1: (appear less in this cluster):\n",
            "                word  tfidf_x   tfidf_y      diff\n",
            "306   automation_rpa  0.00000  0.375625 -0.375625\n",
            "386       healthcare  0.00000  0.375625 -0.375625\n",
            "353          patient  0.00000  0.321964 -0.321964\n",
            "175  robotic_process  0.02852  0.326483 -0.297963\n",
            "393         industry  0.00000  0.214643 -0.214643\n",
            "\n",
            "\n",
            "Negative against Cluster 3: (appear less in this cluster):\n",
            "               word  tfidf_x   tfidf_y      diff\n",
            "215         quantum      0.0  0.391482 -0.391482\n",
            "252  recommendation      0.0  0.391482 -0.391482\n",
            "212            qsvm      0.0  0.249125 -0.249125\n",
            "181             qnn      0.0  0.177946 -0.177946\n",
            "334         machine      0.0  0.177946 -0.177946\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Cluster 3:\n",
            "Positive (appear more in this cluster):\n",
            "               word     tfidf\n",
            "297  recommendation  0.391482\n",
            "290         quantum  0.391482\n",
            "287            qsvm  0.249125\n",
            "364          system  0.210196\n",
            "285             qnn  0.177946\n",
            "\n",
            "\n",
            "Negative against Cluster 1: (appear less in this cluster):\n",
            "                word  tfidf_x   tfidf_y      diff\n",
            "220   automation_rpa      0.0  0.375625 -0.375625\n",
            "326       healthcare      0.0  0.375625 -0.375625\n",
            "170  robotic_process      0.0  0.326483 -0.326483\n",
            "349          patient      0.0  0.321964 -0.321964\n",
            "330         industry      0.0  0.214643 -0.214643\n",
            "\n",
            "\n",
            "Negative against Cluster 2: (appear less in this cluster):\n",
            "            word  tfidf_x   tfidf_y      diff\n",
            "360    detection      0.0  0.375001 -0.375001\n",
            "323          gui      0.0  0.337500 -0.337500\n",
            "324  gui_element      0.0  0.300000 -0.300000\n",
            "381       method      0.0  0.228158 -0.228158\n",
            "333        image      0.0  0.187500 -0.187500\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "from typing import List\n",
        "import random\n",
        "\n",
        "# --- Load Pretrained Model (lightweight but strong for phrases) ---\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def cluster_phrases(phrases: List[str], distance_threshold: float = 1.0) -> List[List[str]]:\n",
        "    if len(phrases) <= 1:\n",
        "        return [phrases]\n",
        "\n",
        "    embeddings = model.encode(phrases)\n",
        "\n",
        "    clustering_model = AgglomerativeClustering(\n",
        "        n_clusters=None,\n",
        "        distance_threshold=distance_threshold,\n",
        "        metric='euclidean',\n",
        "        linkage='ward'\n",
        "    )\n",
        "    clustering_model.fit(embeddings)\n",
        "    labels = clustering_model.labels_\n",
        "\n",
        "    clustered_phrases = {}\n",
        "    for phrase, label in zip(phrases, labels):\n",
        "        clustered_phrases.setdefault(label, []).append(phrase)\n",
        "\n",
        "    return list(clustered_phrases.values())\n",
        "\n",
        "def summarize_cluster(positive_words: List[str], negative_words: List[str], cluster_id: int) -> str:\n",
        "    positive_intro_templates = [\n",
        "        \"This cluster focuses primarily on {}.\",\n",
        "        \"Key topics in this cluster include {}.\",\n",
        "        \"This cluster is characterized by discussions on {}.\"\n",
        "    ]\n",
        "\n",
        "    negative_intro_templates = [\n",
        "        \"It differest the most from clusters including {}\"\n",
        "    ]\n",
        "\n",
        "    clustered_positives = cluster_phrases(positive_words)\n",
        "\n",
        "    # Select one representative per cluster\n",
        "    representatives = [group[0] for group in clustered_positives]\n",
        "\n",
        "    positives = \", \".join(representatives[:-1]) + \", and \" + representatives[-1] if len(representatives) > 1 else representatives[0]\n",
        "    negatives = \", \".join(negative_words[:-1]) + \", and \" + negative_words[-1] if len(negative_words) > 1 else negative_words[0]\n",
        "\n",
        "    summary = f\"Cluster {cluster_id}: \"\n",
        "    summary += random.choice(positive_intro_templates).format(positives)\n",
        "\n",
        "    if negative_words:\n",
        "        summary += \" \" + random.choice(negative_intro_templates).format(negatives)\n",
        "\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "ULC5kuJBsMsV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cluster_terms(cluster_idx):\n",
        "    positive_terms = cluster_keywords[cluster_idx].head(10)['word'].tolist()  # More terms to allow clustering\n",
        "    negative_terms = []\n",
        "    for j in range(len(clusters)):\n",
        "        if cluster_idx != j:\n",
        "            diff = cluster_keywords[i].merge(cluster_keywords[j], on='word', how='left').fillna(0)\n",
        "            diff['diff'] = diff['tfidf_x'] - diff['tfidf_y']\n",
        "            negatives = diff.sort_values('diff', ascending=True).head(3)['word'].tolist()\n",
        "            negative_terms.extend(negatives)\n",
        "    negative_terms = list(set(negative_terms))  # Remove duplicates\n",
        "    return positive_terms, negative_terms\n",
        "\n",
        "for i in range(len(clusters)):\n",
        "  print(summarize_cluster(*get_cluster_terms(i), i + 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISrFTQF0423N",
        "outputId": "cd5f28f5-2d09-49ae-85dc-4cd5fa209484"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 1: This cluster is characterized by discussions on automation_rpa, healthcare, robotic_process, patient, industry, area, and concern. It differest the most from clusters including gui, recommendation, quantum, gui_element, qsvm, and detection\n",
            "Cluster 2: Key topics in this cluster include detection, gui, gui_element, method, image, interface, task, design, and user. It differest the most from clusters including automation_rpa, healthcare, recommendation, quantum, patient, and qsvm\n",
            "Cluster 3: Key topics in this cluster include recommendation, quantum, qsvm, system, qnn, solution, computing, movie, and svm. It differest the most from clusters including automation_rpa, healthcare, gui, robotic_process, gui_element, and detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LM / LLM summarization\n",
        "\n",
        "For this and the next task we will need long-context models. For the most part, long context requires large language models. As Google & Gemini provides free API keys, that is what we will use.\n",
        "\n",
        "For the most part, the output will be composed of two different sections. \"response\", and \"summary\" in the form of a json, which will allow for easier parsing.\n",
        "\n",
        "Furthermore, it is possible that the whole of abstracts in one cluster surpasses the token limit. Thus, we will be selecting from most to less representative (distance to the center of the cluster) until we hit the input token limit."
      ],
      "metadata": {
        "id": "HSnLBglp9LSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_TOKEN=userdata.get('GEMINI_API_TOKEN')\n",
        "MODEL_MAX_TOKENS=1000000"
      ],
      "metadata": {
        "id": "uatE3Zsb5juT"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity # For document similarity\n",
        "\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "def embed_documents(docs: List[str], model_name: str = \"all-MiniLM-L6-v2\") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    This function creates embeddings of the different clusters so we can compute the similarity between them and, thu\n",
        "    calculate which of the abstract represent better the cluster\n",
        "    \"\"\"\n",
        "    model = SentenceTransformer(model_name)\n",
        "    embeddings = model.encode(docs, convert_to_numpy=True, normalize_embeddings=True)\n",
        "    return embeddings\n",
        "\n",
        "def select_representative_subset(\n",
        "    docs: List[str],\n",
        "    max_tokens: int,\n",
        "    embedding_model: str = \"all-MiniLM-L6-v2\",\n",
        ") -> Tuple[List[str], int]:\n",
        "    embeddings = embed_documents(docs, model_name=embedding_model)\n",
        "    centroid = np.mean(embeddings, axis=0, keepdims=True)\n",
        "    similarities = cosine_similarity(embeddings, centroid).flatten()\n",
        "    token_counts = list(\n",
        "        map(\n",
        "            lambda x: client.models.count_tokens(model=\"gemini-2.0-flash\", contents=x).total_tokens,\n",
        "            docs\n",
        "        )\n",
        "    )\n",
        "\n",
        "    ranked_indices = np.argsort(-similarities)  # descending order\n",
        "    selected_docs = []\n",
        "    total_tokens = 0\n",
        "\n",
        "    for idx in ranked_indices:\n",
        "        doc_tokens = token_counts[idx]\n",
        "        if total_tokens + doc_tokens <= max_tokens:\n",
        "            selected_docs.append(docs[idx])\n",
        "            total_tokens += doc_tokens\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return selected_docs, total_tokens\n",
        "\n",
        "select_representative_subset(clusters[0], MODEL_MAX_TOKENS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg6HjZwdk6zi",
        "outputId": "2e0d8591-7533-4ae6-f208-3eb1330242f8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['An emerging technology breakthrough called robotic process automation (RPA) is being designed to alleviate users’ everyday responsibilities of tedious and monotonous operations. This technology presents the fraternity of researchers with a brand-new field of study, and several research investigations are now being conducted in this area. It isn’t robotics; rather, it represents completely distinct area of technology. Robotic process automation is a new as well as rapidly expanding area of robotic systems. This study highlights the significant features of robotic process automation (RPA) and its application in healthcare industry.',\n",
              "  'Robotic process automation (RPA) is transforming the healthcare industry through the automation of jobs, optimisation of workflows, and improvement of operational efficiency. This chapter examines the revolutionary capacity of robotic process automation (RPA), emphasising its various uses, advantages, and ethical implications. Although RPA enhances the efficiency of resource allocation and enhances the quality of patient care, it is crucial to tackle concerns such as job displacement and data privacy. Empirical case studies provide concrete evidence of the tangible effects of robotic process automation (RPA) on the delivery of healthcare services. Anticipating and adopting the progress of robotic process automation (RPA) with ethical accountability holds the potential for a more streamlined and patient-focused healthcare system.',\n",
              "  'With the advent of Technology in the healthcare industry, there is a growth in revenue generation. Patients, doctors, insurance companies, and other entities are the key players in Healthcare Industry. Further effective and accurate back workplace method is urgently needed towards maintaining poise among the growing number of patients and the paperwork required for development plus insurance prerogatives, among other things. Hence, this concerns progressive mechanisation elucidations such as Robotic Process Automation (RPA) being able to assist healthcare organisations in increasing effective proficiency, lowering expenses, and reducing the risk of human error once handling data such as doctor credentialing, staffing, and patient fitness, as well as medical record maintenance, payables and denial recover, and patient scheduling.'],\n",
              " 394)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SUMMARY_SYS_PROMPT = \"\"\"\n",
        "# Role\n",
        "You are a very experienced and skilled researchered and reviewer. You are tasked with finding similarities and summarizing a set of works, describing what they have in common and what, overall, represents the cluster of documents given to you.\n",
        "\n",
        "A prior processing of the cluster of documents has been carried out, and some terms were found to be relevant. On the other hand, there were also negative terms found, indicating that the given contents do not resemble those topics, or not as much as other clusters which will not be provided to you.\n",
        "\n",
        "Please bear in mind that negative terms do not mean the papers do not talk about it, but take it into account as they may not be the sole reason, or the primary characteristic of the given works.\n",
        "\n",
        "# Input format\n",
        "You will be given the following inputs in the form of a json:\n",
        "{\n",
        "  'abstracts': list[str], // A list of abstracts, each of which corresping to a different article\n",
        "  'positive_terms': list[str], // A set of terms that are commonly found in those abstracts\n",
        "  'negative_terms': list[str], // A set of terms that are less common in the set of abstracts given than other clusters not provided to you\n",
        "}\n",
        "\n",
        "# Output format\n",
        "You are to return a output using the following JSON Schema:\n",
        "Summary = {'reasoning': str, 'summary': str}\n",
        "\"\"\"\n",
        "\n",
        "SUMMARY_PROMPT = \"\"\"\n",
        "# Inputs:\n",
        "{{\n",
        "  'abstracts': {}\n",
        "  'positive_terms': {}\n",
        "  'negative_terms': {}\n",
        "}}\n",
        "\n",
        "# Output:\n",
        "\"\"\"\n",
        "\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Summary(BaseModel):\n",
        "  reasoning: str\n",
        "  summary: str"
      ],
      "metadata": {
        "id": "MYAYSKlEm5nF"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "import json\n",
        "\n",
        "def summarize_cluster(docs: List[str], positive_terms: List[str], negative_terms: List[str]) -> str:\n",
        "    reduced_docs = select_representative_subset(docs, MODEL_MAX_TOKENS)[0]\n",
        "\n",
        "    prompt = SUMMARY_PROMPT.format(reduced_docs, positive_terms, negative_terms)\n",
        "\n",
        "    chat = client.chats.create(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        history=[\n",
        "            types.Content(\n",
        "                role=\"user\", parts=[types.Part(text=SUMMARY_SYS_PROMPT)]\n",
        "            )\n",
        "        ],\n",
        "        config={\n",
        "          'response_mime_type': 'application/json',\n",
        "          'response_schema': Summary,\n",
        "        },\n",
        "    )\n",
        "\n",
        "    response = chat.send_message(\n",
        "        message=prompt,\n",
        "    )\n",
        "\n",
        "    return response\n",
        "\n",
        "for i in range(len(clusters)):\n",
        "  positive_terms, negative_terms = get_cluster_terms(i)\n",
        "  summary = summarize_cluster(clusters[i], positive_terms, negative_terms)\n",
        "  print(f\"============ CLUSTER {i+1} SUMMARY =============\")\n",
        "  json_text = json.loads(summary.text)\n",
        "  # Print json pretty formatted\n",
        "  print(json.dumps(json_text, indent=2))\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-Z52SdzrjkE",
        "outputId": "76d201bc-6d39-4074-b945-9d730b8c6884"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============ CLUSTER 1 SUMMARY =============\n",
            "{\n",
            "  \"reasoning\": \"The abstracts discuss the application of Robotic Process Automation (RPA) in the healthcare industry. They highlight RPA's ability to improve efficiency, reduce errors, and automate various processes related to patient care, insurance, and data management. The terms 'automation_rpa', 'healthcare', 'robotic_process', 'patient', 'industry', 'technology', 'area', 'automation', and 'insurance' from positive_terms are all strongly related to the central themes of the abstracts. The negative terms are not mentioned and are not relevant.\",\n",
            "  \"summary\": \"These abstracts discuss the transformative impact of Robotic Process Automation (RPA) on the healthcare industry. RPA automates tasks, optimizes workflows, enhances efficiency, and reduces errors in areas such as patient care, insurance processing, data handling, and resource allocation. While addressing concerns like job displacement and data privacy is important, RPA holds the potential to streamline healthcare systems and improve patient focus.\"\n",
            "}\n",
            "\n",
            "\n",
            "============ CLUSTER 2 SUMMARY =============\n",
            "{\n",
            "  \"reasoning\": \"The abstracts discuss GUI element detection and UI reconstruction. The positive terms strongly relate to the content of the abstracts. The negative terms do not appear to be relevant based on the content.\",\n",
            "  \"summary\": \"The provided abstracts discuss methods and designs for GUI element detection and UI reconstruction, focusing on improving accuracy, recall, and efficiency in tasks such as code generation and automated process analysis.\"\n",
            "}\n",
            "\n",
            "\n",
            "============ CLUSTER 3 SUMMARY =============\n",
            "{\n",
            "  \"reasoning\": \"The abstracts discuss the application of quantum computing in recommendation systems, focusing on improving efficiency, accuracy, and electrical consumption. The positive terms provided (recommendation, quantum, qsvm, system, qnn, machine, solution, computing, movie, svm) are all central to the topics covered in the abstracts. The negative terms (automation_rpa, healthcare, gui, robotic_process, gui_element, detection) are unrelated to the content of the abstracts.\",\n",
            "  \"summary\": \"The abstracts explore the use of quantum computing to enhance recommendation systems. They investigate quantum solutions' efficiency, accuracy, and electrical consumption compared to traditional methods. Quantum Support Vector Machines (QSVM) and Quantum Neural Networks (QNN) are evaluated for movie recommendations, demonstrating improved performance over classical approaches. The studies highlight the potential of quantum computing in recommender systems and suggest future research directions.\"\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LM/LLM cluster 1:1 comparison"
      ],
      "metadata": {
        "id": "xLBaXNihXv5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COMPARISON_SYS_PROMPT = \"\"\"\n",
        "# Role\n",
        "You are a very experienced and skilled researchered and reviewer. You are tasked with comparing two different clusters of research papers, describing their similarities and differences in a comprehensive way.\n",
        "\n",
        "A prior processing of the clusters of documents has been carried out, and some terms were found to be relevant for each cluster. For each cluster, some terms were found to be less relevant, indicating that the given contents do not resemble those topics, or not as much as other clusters which will not be provided to you.\n",
        "\n",
        "Please bear in mind that negative terms do not mean the papers do not talk about it, but take it into account as they may not be the sole reason, or the primary characteristic of the given works.\n",
        "\n",
        "# Input format\n",
        "You will be given the following inputs in the form of a json:\n",
        "{\n",
        "  'cluster1': {\n",
        "    'abstracts': list[str], // A list of abstracts, each of which corresponding to a different article in cluster 1\n",
        "    'positive_terms': list[str], // A set of terms that are commonly found in those abstracts of cluster 1\n",
        "    'negative_terms': list[str] // A set of terms that are less common in the set of abstracts given in cluster 1 than other clusters not provided to you\n",
        "  },\n",
        "  'cluster2': {\n",
        "    'abstracts': list[str], // A list of abstracts, each of which corresponding to a different article in cluster 2\n",
        "    'positive_terms': list[str], // A set of terms that are commonly found in those abstracts of cluster 2\n",
        "    'negative_terms': list[str] // A set of terms that are less common in the set of abstracts given in cluster 2 than other clusters not provided to you\n",
        "  }\n",
        "}\n",
        "\n",
        "# Output format\n",
        "You are to return a output using the following JSON Schema:\n",
        "Comparison = {\n",
        "    'reasoning': str, // Description of the similarities and differences between the two clusters\n",
        "    'overlap': str, // Description of overlapping topics and concepts between the two clusters\n",
        "    'differences': str // Description of the main differences in topics, concepts and approaches between the two clusters\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "COMPARISON_PROMPT = \"\"\"\n",
        "# Inputs:\n",
        "{{\n",
        "  'cluster1': {{\n",
        "    'abstracts': {},\n",
        "    'positive_terms': {},\n",
        "    'negative_terms': {}\n",
        "  }},\n",
        "  'cluster2': {{\n",
        "    'abstracts': {},\n",
        "    'positive_terms': {},\n",
        "    'negative_terms': {}\n",
        "  }}\n",
        "}}\n",
        "\n",
        "# Output:\n",
        "\"\"\"\n",
        "\n",
        "class Comparison(BaseModel):\n",
        "    reasoning: str\n",
        "    overlap: str\n",
        "    differences: str\n",
        "\n",
        "def compare_clusters(cluster1_docs, cluster1_positive_terms, cluster1_negative_terms,\n",
        "                     cluster2_docs, cluster2_positive_terms, cluster2_negative_terms):\n",
        "\n",
        "    reduced_cluster1_docs = select_representative_subset(cluster1_docs, MODEL_MAX_TOKENS/2)[0]\n",
        "    reduced_cluster2_docs = select_representative_subset(cluster2_docs, MODEL_MAX_TOKENS/2)[0]\n",
        "\n",
        "    prompt = COMPARISON_PROMPT.format(\n",
        "        reduced_cluster1_docs, cluster1_positive_terms, cluster1_negative_terms,\n",
        "        reduced_cluster2_docs, cluster2_positive_terms, cluster2_negative_terms\n",
        "    )\n",
        "\n",
        "    chat = client.chats.create(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        history=[\n",
        "            types.Content(\n",
        "                role=\"user\", parts=[types.Part(text=COMPARISON_SYS_PROMPT)]\n",
        "            )\n",
        "        ],\n",
        "        config={\n",
        "          'response_mime_type': 'application/json',\n",
        "          'response_schema': Comparison,\n",
        "        },\n",
        "    )\n",
        "\n",
        "    response = chat.send_message(message=prompt)\n",
        "    return response\n",
        "\n",
        "# Example usage\n",
        "cluster1_idx = 0\n",
        "cluster2_idx = 1\n",
        "\n",
        "cluster1_positive_terms, cluster1_negative_terms = get_cluster_terms(cluster1_idx)\n",
        "cluster2_positive_terms, cluster2_negative_terms = get_cluster_terms(cluster2_idx)\n",
        "\n",
        "comparison_result = compare_clusters(\n",
        "    clusters[cluster1_idx], cluster1_positive_terms, cluster1_negative_terms,\n",
        "    clusters[cluster2_idx], cluster2_positive_terms, cluster2_negative_terms\n",
        ")\n",
        "\n",
        "print(f\"============ CLUSTER {cluster1_idx + 1} vs CLUSTER {cluster2_idx + 1} COMPARISON =============\")\n",
        "json_text = json.loads(comparison_result.text)\n",
        "print(json.dumps(json_text, indent=2))\n"
      ],
      "metadata": {
        "id": "bQwjWQJUXyLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017b1d77-f00d-43b6-e6a5-4456a1e9a059"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============ CLUSTER 1 vs CLUSTER 2 COMPARISON =============\n",
            "{\n",
            "  \"reasoning\": \"Cluster 1 focuses on the application of Robotic Process Automation (RPA) in the healthcare industry, highlighting its benefits, challenges, and ethical considerations. Cluster 2, however, centers around the detection of Graphical User Interface (GUI) elements in images, with applications in software engineering tasks and UI analysis. Both clusters deal with automation and improving efficiency, but in vastly different contexts.\",\n",
            "  \"overlap\": \"Both clusters touch on the broad concept of 'automation' and process improvement. Both also relate to 'technology' to some extent. The term 'interface' could be considered an area of semantic overlap as RPA often involves interacting with existing system interfaces, and cluster 2 explicitly deals with user interfaces.\",\n",
            "  \"differences\": \"Cluster 1 is strongly focused on 'healthcare', 'robotic process automation (RPA)', and related terms like 'patient' and 'insurance'. It emphasizes the 'industry' context and the 'application' of RPA. Cluster 2, on the other hand, is geared towards 'GUI element detection', 'graphical user interfaces (GUI)', 'UI', 'image analysis', and 'software engineering tasks'. It uses terms like 'method', 'design', and 'task', indicating a focus on technical implementation and problem-solving within the domain of user interface analysis.\"\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}