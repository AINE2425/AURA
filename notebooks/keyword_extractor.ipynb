{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdLgg6JoSfqf"
      },
      "source": [
        "# Keyword extractor\n",
        "\n",
        "1. We use a model from the Sentence Transformers library (https://huggingface.co/sentence-transformers) to generate sentence embeddings. Mean pooling is applied to obtain a single vector per text for simplification.\n",
        "2. We use KeyBERT (https://maartengr.github.io/KeyBERT/) to extract key phrases from the abstract, utilizing the previously generated embeddings.\n",
        "3. We create a prompt using the abstract and key phrases, asking for the generation of 5 keywords for the article.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "yv5Fk-s05plL",
        "outputId": "d7b5104a-2bed-4cac-d7c8-1193a7aa1d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìù Extracted Key Phrases:\n",
            "['sentiment analysis method', 'understanding sentiment analysis', 'sentiment analysis providing', 'sentiment analysis scrutinizing', 'sentiment analysis', 'sentiment analysis gaining', 'sentiment analysis covering', 'sentiment analysis proposed', 'significance sentiment analysis', 'encountered sentiment analysis']\n",
            "\n",
            "üîë Prompt for Gemini:\n",
            "\n",
            "    Given the following abstract and a list of detected key phrases, generate 5 clean and normalized keywords that best summarize the article.\n",
            "    Only provide the keywords, separated by commas, with no additional information.\n",
            "\n",
            "    Abstract:\n",
            "    \n",
            "Sentiment analysis is a method within natural language processing that evaluates and identifies the emotional\n",
            "tone or mood conveyed in textual data. Scrutinizing words and phrases categorizes them into positive, negative,\n",
            "or neutral sentiments. The significance of sentiment analysis lies in its capacity to derive valuable insights\n",
            "from extensive textual data, empowering businesses to grasp customer sentiments, make informed choices,\n",
            "and enhance their offerings. For the further advancement of sentiment analysis, gaining a deep understanding\n",
            "of its algorithms, applications, current performance, and challenges is imperative. Therefore, in this extensive\n",
            "survey, we began exploring the vast array of application domains for sentiment analysis, scrutinizing them\n",
            "within the context of existing research. We then delved into prevalent pre-processing techniques, datasets,\n",
            "and evaluation metrics to enhance comprehension. We also explored Machine Learning, Deep Learning, Large\n",
            "Language Models and Pre-trained models in sentiment analysis, providing insights into their advantages and\n",
            "drawbacks. Subsequently, we precisely reviewed the experimental results and limitations of recent state-of-the-art articles.\n",
            "Finally, we discussed the diverse challenges encountered in sentiment analysis and proposed\n",
            "future research directions to mitigate these concerns. This extensive review provides a complete understanding\n",
            "of sentiment analysis, covering its models, application domains, results analysis, challenges, and research\n",
            "directions.\n",
            "\n",
            "\n",
            "    Detected Key Phrases:\n",
            "    sentiment analysis method, understanding sentiment analysis, sentiment analysis providing, sentiment analysis scrutinizing, sentiment analysis, sentiment analysis gaining, sentiment analysis covering, sentiment analysis proposed, significance sentiment analysis, encountered sentiment analysis\n",
            "\n",
            "    Keywords (separated by commas):\n",
            "    \n",
            "\n",
            "üéØ Keywords generated by Gemini:\n",
            "Sentiment Analysis, Natural Language Processing, Machine Learning, Deep Learning, Textual Data\n",
            "\n",
            "üëÅÔ∏è Expected keywords were:\n",
            "Sentiment classification, Text classification, Natural language processing, Emotion detection, Sentiment analysis\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from keybert import KeyBERT # !pip install keybert\n",
        "\n",
        "# Gemini API setup\n",
        "genai.configure(api_key=\"GEMINI_API_KEY\")\n",
        "\n",
        "# Load model for sentence embedding\n",
        "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Function to get text embeddings\n",
        "def embed_text(texts):\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "\n",
        "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**encoded_input)\n",
        "\n",
        "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "    return embeddings\n",
        "\n",
        "# Mean pooling function to get a single vector per text\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "# Create KeyBERT with the embedding function\n",
        "kw_model = KeyBERT(model=embed_text)\n",
        "\n",
        "# Example abstract (expected keywords are: Sentiment classification, Text classification, Natural language processing, Emotion detection, Sentiment analysis)\n",
        "abstract = \"\"\"\n",
        "Sentiment analysis is a method within natural language processing that evaluates and identifies the emotional\n",
        "tone or mood conveyed in textual data. Scrutinizing words and phrases categorizes them into positive, negative,\n",
        "or neutral sentiments. The significance of sentiment analysis lies in its capacity to derive valuable insights\n",
        "from extensive textual data, empowering businesses to grasp customer sentiments, make informed choices,\n",
        "and enhance their offerings. For the further advancement of sentiment analysis, gaining a deep understanding\n",
        "of its algorithms, applications, current performance, and challenges is imperative. Therefore, in this extensive\n",
        "survey, we began exploring the vast array of application domains for sentiment analysis, scrutinizing them\n",
        "within the context of existing research. We then delved into prevalent pre-processing techniques, datasets,\n",
        "and evaluation metrics to enhance comprehension. We also explored Machine Learning, Deep Learning, Large\n",
        "Language Models and Pre-trained models in sentiment analysis, providing insights into their advantages and\n",
        "drawbacks. Subsequently, we precisely reviewed the experimental results and limitations of recent state-of-the-art articles.\n",
        "Finally, we discussed the diverse challenges encountered in sentiment analysis and proposed\n",
        "future research directions to mitigate these concerns. This extensive review provides a complete understanding\n",
        "of sentiment analysis, covering its models, application domains, results analysis, challenges, and research\n",
        "directions.\n",
        "\"\"\"\n",
        "\n",
        "# Extract keywords with KeyBERT\n",
        "keywords = kw_model.extract_keywords(\n",
        "    abstract,\n",
        "    keyphrase_ngram_range=(1, 3), # Key phrases from 1 to 3 words\n",
        "    stop_words='english',\n",
        "    top_n=10  # Number of key phrases to extract\n",
        ")\n",
        "\n",
        "# Extract key phrases from KeyBERT's result\n",
        "key_phrases = [kw[0] for kw in keywords]\n",
        "\n",
        "print(\"\\nüìù Extracted Key Phrases:\")\n",
        "print(key_phrases)\n",
        "\n",
        "# Function to build the prompt for Gemini\n",
        "def build_prompt(abstract, key_phrases):\n",
        "    key_phrases_str = \", \".join(key_phrases)\n",
        "    prompt = f\"\"\"\n",
        "    Given the following abstract and a list of detected key phrases, generate 5 clean and normalized keywords that best summarize the article.\n",
        "    Only provide the keywords, separated by commas, with no additional information.\n",
        "\n",
        "    Abstract:\n",
        "    {abstract}\n",
        "\n",
        "    Detected Key Phrases:\n",
        "    {key_phrases_str}\n",
        "\n",
        "    Keywords (separated by commas):\n",
        "    \"\"\"\n",
        "    return prompt\n",
        "\n",
        "prompt = build_prompt(abstract, key_phrases)\n",
        "\n",
        "print(\"\\nüîë Prompt for Gemini:\")\n",
        "print(prompt)\n",
        "\n",
        "# Function to generate keywords using Gemini\n",
        "def generate_keywords_gemini(prompt):\n",
        "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "keywords_from_gemini = generate_keywords_gemini(prompt)\n",
        "\n",
        "# Show result\n",
        "print(\"\\nüéØ Keywords generated by Gemini:\")\n",
        "print(keywords_from_gemini)\n",
        "\n",
        "print(\"\\nüëÅÔ∏è Expected keywords were:\")\n",
        "print(\"Sentiment classification, Text classification, Natural language processing, Emotion detection, Sentiment analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6uTtosUU6dK"
      },
      "source": [
        "### Paper search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the arXiv API to search for papers  using a list of keywords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "juDn9bfKU6Ju"
      },
      "outputs": [],
      "source": [
        "import arxiv  # !pip install arxiv\n",
        "\n",
        "def get_abstracts_by_keywords(keywords, max_results=15):\n",
        "    if len(keywords) == 0:\n",
        "        raise ValueError(\"At least one keyword must be provided.\")\n",
        "    else:\n",
        "        keywords = keywords[:3]\n",
        "        search_query = \" AND \".join(f'\"{kw.strip()}\"' for kw in keywords)\n",
        "\n",
        "    search = arxiv.Search(\n",
        "        query=search_query,\n",
        "        max_results=max_results,\n",
        "        sort_by=arxiv.SortCriterion.Relevance,\n",
        "        sort_order=arxiv.SortOrder.Descending,\n",
        "    )\n",
        "\n",
        "    client = arxiv.Client()\n",
        "    results = {}\n",
        "\n",
        "    for result in client.results(search):\n",
        "        results[result.title] = {\n",
        "            \"abstract\": result.summary,\n",
        "            \"url\": result.entry_id\n",
        "        }\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdmt_hclV3ax",
        "outputId": "422565bd-7478-42bd-e9c5-a27f357966ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: Sentiment analysis and opinion mining on E-commerce site\n",
            "URL: http://arxiv.org/abs/2211.15536v2\n",
            "Abstract: Sentiment analysis or opinion mining help to illustrate the phrase NLP\n",
            "(Natural Language Processing). Sentiment analysis has been the most significant\n",
            "topic in recent years. The goal of this study is to solve the sentiment\n",
            "polarity classification challenges in sentiment analysis. A broad technique for\n",
            "categorizing sentiment opposition is presented, along with comprehensive\n",
            "process explanations. With the results of the analysis, both sentence-level\n",
            "classification and review-level categorization are conducted. Finally, we\n",
            "discuss our plans for future sentiment analysis research.\n",
            "\n",
            "Title: Twitter Sentiment Analysis System\n",
            "URL: http://arxiv.org/abs/1807.07752v1\n",
            "Abstract: Social media is increasingly used by humans to express their feelings and\n",
            "opinions in the form of short text messages. Detecting sentiments in the text\n",
            "has a wide range of applications including identifying anxiety or depression of\n",
            "individuals and measuring well-being or mood of a community. Sentiments can be\n",
            "expressed in many ways that can be seen such as facial expression and gestures,\n",
            "speech and by written text. Sentiment Analysis in text documents is essentially\n",
            "a content-based classification problem involving concepts from the domains of\n",
            "Natural Language Processing as well as Machine Learning. In this paper,\n",
            "sentiment recognition based on textual data and the techniques used in\n",
            "sentiment analysis are discussed.\n",
            "\n",
            "Title: Grammar Detection for Sentiment Analysis through Improved Viterbi Algorithm\n",
            "URL: http://arxiv.org/abs/2205.13148v2\n",
            "Abstract: Grammar Detection, also referred to as Parts of Speech Tagging of raw text,\n",
            "is considered an underlying building block of the various Natural Language\n",
            "Processing pipelines like named entity recognition, question answering, and\n",
            "sentiment analysis. In short, forgiven a sentence, Parts of Speech tagging is\n",
            "the task of specifying and tagging each word of a sentence with nouns, verbs,\n",
            "adjectives, adverbs, and more. Sentiment Analysis may well be a procedure\n",
            "accustomed to determining if a given sentence's emotional tone is neutral,\n",
            "positive or negative. To assign polarity scores to the thesis or entities\n",
            "within phrase, in-text analysis and analytics, machine learning and natural\n",
            "language processing, approaches are incorporated. This Sentiment Analysis using\n",
            "POS tagger helps us urge a summary of the broader public over a specific topic.\n",
            "For this, we are using the Viterbi algorithm, Hidden Markov Model, Constraint\n",
            "based Viterbi algorithm for POS tagging. By comparing the accuracies, we select\n",
            "the foremost accurate result of the model for Sentiment Analysis for\n",
            "determining the character of the sentence.\n",
            "\n",
            "Title: Enhance Multi-domain Sentiment Analysis of Review Texts through Prompting Strategies\n",
            "URL: http://arxiv.org/abs/2309.02045v2\n",
            "Abstract: Large Language Models (LLMs) have made significant strides in both scientific\n",
            "research and practical applications. Existing studies have demonstrated the\n",
            "state-of-the-art (SOTA) performance of LLMs in various natural language\n",
            "processing tasks. However, the question of how to further enhance LLMs'\n",
            "performance in specific task using prompting strategies remains a pivotal\n",
            "concern. This paper explores the enhancement of LLMs' performance in sentiment\n",
            "analysis through the application of prompting strategies. We formulate the\n",
            "process of prompting for sentiment analysis tasks and introduce two novel\n",
            "strategies tailored for sentiment analysis: RolePlaying (RP) prompting and\n",
            "Chain-of-thought (CoT) prompting. Specifically, we also propose the RP-CoT\n",
            "prompting strategy which is a combination of RP prompting and CoT prompting. We\n",
            "conduct comparative experiments on three distinct domain datasets to evaluate\n",
            "the effectiveness of the proposed sentiment analysis strategies. The results\n",
            "demonstrate that the adoption of the proposed prompting strategies leads to a\n",
            "increasing enhancement in sentiment analysis accuracy. Further, the CoT\n",
            "prompting strategy exhibits a notable impact on implicit sentiment analysis,\n",
            "with the RP-CoT prompting strategy delivering the most superior performance\n",
            "among all strategies.\n",
            "\n",
            "Title: A Comprehensive Survey on Aspect Based Sentiment Analysis\n",
            "URL: http://arxiv.org/abs/2006.04611v1\n",
            "Abstract: Aspect Based Sentiment Analysis (ABSA) is the sub-field of Natural Language\n",
            "Processing that deals with essentially splitting our data into aspects ad\n",
            "finally extracting the sentiment information. ABSA is known to provide more\n",
            "information about the context than general sentiment analysis. In this study,\n",
            "our aim is to explore the various methodologies practiced while performing\n",
            "ABSA, and providing a comparative study. This survey paper discusses various\n",
            "solutions in-depth and gives a comparison between them. And is conveniently\n",
            "divided into sections to get a holistic view on the process.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "papers = get_abstracts_by_keywords([kw.strip() for kw in keywords_from_gemini.split(',')], max_results=5)\n",
        "\n",
        "for title, data in papers.items():\n",
        "    print(f\"Title: {title}\")\n",
        "    print(f\"URL: {data['url']}\")\n",
        "    print(f\"Abstract: {data['abstract']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQT4Dav016Ug"
      },
      "source": [
        "### Test with several abstracts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "etfIW7xxve5i",
        "outputId": "ce7c0eb4-7ec8-4749-f1c5-49f9743b68e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÑ Abstract 1\n",
            "üéØ Keywords generated by Gemini: Sentiment Analysis, Natural Language Processing, Machine Learning, Deep Learning, Textual Data\n",
            "üëÅÔ∏è Expected keywords were: ['Sentiment classification', 'Text classification', 'Natural language processing', 'Emotion detection', 'Sentiment analysis']\n",
            "‚úÖ Matches found: 2 of 5\n",
            "\n",
            "üìÑ Abstract 2\n",
            "üéØ Keywords generated by Gemini: smart cities, smart city, urban intelligence, city measurement, urban transformation\n",
            "üëÅÔ∏è Expected keywords were: ['Smart City', 'Measurement', 'Ranking', 'Framework', 'Model', 'Planning', 'Project']\n",
            "‚úÖ Matches found: 1 of 5\n",
            "\n",
            "üìÑ Abstract 3\n",
            "üéØ Keywords generated by Gemini: Apache Spark, big data analytics, cluster computing, machine learning, stream processing\n",
            "üëÅÔ∏è Expected keywords were: ['Big data', 'Data analysis', 'Distributed and parallel computing', 'Cluster computing', 'Apache Spark', 'Machine learning', 'Graph analysis', 'Stream processing', 'Resilient Distributed Datasets']\n",
            "‚úÖ Matches found: 4 of 5\n",
            "\n",
            "üìÑ Abstract 4\n",
            "üéØ Keywords generated by Gemini: Football, Social Learning, Aggression, Fans, Sociology\n",
            "üëÅÔ∏è Expected keywords were: ['Football', 'Fans', 'Aggression', 'Fan behavior', 'Social learning theory']\n",
            "‚úÖ Matches found: 3 of 5\n",
            "\n",
            "üìÑ Abstract 5\n",
            "üéØ Keywords generated by Gemini: Plant foods, Bioactive compounds, Health benefits, Functional foods, Metabolic disorders\n",
            "üëÅÔ∏è Expected keywords were: ['plant foods', 'bioactive components', 'antioxidants', 'polyphenols', 'anti-inflammatory', 'chronic diseases', 'human health', 'gut health']\n",
            "‚úÖ Matches found: 1 of 5\n",
            "\n",
            "üìÑ Abstract 6\n",
            "üéØ Keywords generated by Gemini: COVID-19, mathematical model, media impact, reproduction number, disease stability\n",
            "üëÅÔ∏è Expected keywords were: ['COVID-19 mitigation', 'Media coverage', 'Mathematical study', 'Sensitivity analysis', 'Herd immunity', 'Numerical simulation']\n",
            "‚úÖ Matches found: 0 of 5\n",
            "\n",
            "üìÑ Abstract 7\n",
            "üéØ Keywords generated by Gemini: online mapping, google maps, criminology, research methods, environmental criminology\n",
            "üëÅÔ∏è Expected keywords were: ['Google Maps', 'Street View', 'Environmental criminology', 'Innovation', 'Methodology', 'Methods']\n",
            "‚úÖ Matches found: 2 of 5\n",
            "\n",
            "üìÑ Abstract 8\n",
            "üéØ Keywords generated by Gemini: Mars, Food Production, In-Situ Resource Utilization, Hydroponics, Sustainable Colonization\n",
            "üëÅÔ∏è Expected keywords were: ['Mars', 'In-situ food production', 'Single-cell proteins', 'Insect farming', '3-D food printing', 'Synthetic biology']\n",
            "‚úÖ Matches found: 1 of 5\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from keybert import KeyBERT  # !pip install keybert\n",
        "\n",
        "# Gemini API setup\n",
        "genai.configure(api_key=\"GEMINI_API_KEY\")\n",
        "\n",
        "# Load model for sentence embedding\n",
        "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Function to get text embeddings\n",
        "def embed_text(texts):\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**encoded_input)\n",
        "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "    return embeddings\n",
        "\n",
        "# Mean pooling function to get a single vector per text\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "# Create KeyBERT with the embedding function\n",
        "kw_model = KeyBERT(model=embed_text)\n",
        "\n",
        "# Function to build the prompt for Gemini\n",
        "def build_prompt(abstract, key_phrases):\n",
        "    key_phrases_str = \", \".join(key_phrases)\n",
        "    prompt = f\"\"\"\n",
        "    Given the following abstract and a list of detected key phrases, generate 5 clean and normalized keywords that best summarize the article.\n",
        "    Only provide the keywords, separated by commas, with no additional information.\n",
        "\n",
        "    Abstract:\n",
        "    {abstract}\n",
        "\n",
        "    Detected Key Phrases:\n",
        "    {key_phrases_str}\n",
        "\n",
        "    Keywords (separated by commas):\n",
        "    \"\"\"\n",
        "    return prompt\n",
        "\n",
        "# Function to generate keywords using Gemini\n",
        "def generate_keywords_gemini(prompt):\n",
        "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "# Function to compare keywords (case-insensitive, trimmed)\n",
        "def count_matches(generated, expected):\n",
        "    gen_set = {kw.strip().lower() for kw in generated.split(',')}\n",
        "    exp_set = {kw.strip().lower() for kw in expected}\n",
        "    return len(gen_set & exp_set)\n",
        "\n",
        "# Main function to process abstracts and expected keywords\n",
        "def process_abstracts(abstracts, expected_keywords_list):\n",
        "    results = []\n",
        "    for abstract, expected_keywords in zip(abstracts, expected_keywords_list):\n",
        "        keywords = kw_model.extract_keywords(\n",
        "            abstract,\n",
        "            keyphrase_ngram_range=(1, 3),\n",
        "            stop_words='english',\n",
        "            top_n=10\n",
        "        )\n",
        "        key_phrases = [kw[0] for kw in keywords]\n",
        "        prompt = build_prompt(abstract, key_phrases)\n",
        "        gemini_keywords = generate_keywords_gemini(prompt)\n",
        "        match_count = count_matches(gemini_keywords, expected_keywords)\n",
        "        results.append({\n",
        "            \"abstract\": abstract,\n",
        "            \"key_phrases\": key_phrases,\n",
        "            \"gemini_keywords\": gemini_keywords,\n",
        "            \"expected_keywords\": expected_keywords,\n",
        "            \"match_count\": match_count\n",
        "        })\n",
        "    return results\n",
        "\n",
        "abstracts = [\n",
        "    \"\"\"Sentiment analysis is a method within natural language processing that evaluates and identifies the emotional\n",
        "    tone or mood conveyed in textual data. Scrutinizing words and phrases categorizes them into positive, negative,\n",
        "    or neutral sentiments. The significance of sentiment analysis lies in its capacity to derive valuable insights\n",
        "    from extensive textual data, empowering businesses to grasp customer sentiments, make informed choices,\n",
        "    and enhance their offerings. For the further advancement of sentiment analysis, gaining a deep understanding\n",
        "    of its algorithms, applications, current performance, and challenges is imperative. Therefore, in this extensive\n",
        "    survey, we began exploring the vast array of application domains for sentiment analysis, scrutinizing them\n",
        "    within the context of existing research. We then delved into prevalent pre-processing techniques, datasets,\n",
        "    and evaluation metrics to enhance comprehension. We also explored Machine Learning, Deep Learning, Large\n",
        "    Language Models and Pre-trained models in sentiment analysis, providing insights into their advantages and\n",
        "    drawbacks. Subsequently, we precisely reviewed the experimental results and limitations of recent state-of-the-art articles.\n",
        "    Finally, we discussed the diverse challenges encountered in sentiment analysis and proposed\n",
        "    future research directions to mitigate these concerns. This extensive review provides a complete understanding\n",
        "    of sentiment analysis, covering its models, application domains, results analysis, challenges, and research\n",
        "    directions.\"\"\",\n",
        "\n",
        "    \"\"\"Smart cities are an international phenomenon. Many cities are actively working to build or transform their models toward that of a Smart City.\n",
        "    There is constant research and reports devoted to measuring the intelligence of cities through establishing specific methodologies and indicators\n",
        "    (grouped by various criteria). We believe the subject lacks a certain uniformity, which we aim to redress in this paper by suggesting a framework\n",
        "    for properly measuring the smart level of a city. Cities are complex and heterogeneous structures, which complicates comparisons between them.\n",
        "    To address this we propose an N--dimensional measurement framework where each level or dimension supplies information of interest that is evaluated\n",
        "    independently. As a result, the measure of a city's intelligence is the result of the evaluations obtained for each of these levels. To this end,\n",
        "    we have typified the transformation (city to smart city) and the measurement (smart city ranking) processes.\"\"\",\n",
        "\n",
        "    \"\"\"Apache Spark has emerged as the de facto framework for big data analytics with its advanced in-memory programming model and upper-level libraries\n",
        "    for scalable machine learning, graph analysis, streaming and structured data processing. It is a general-purpose cluster computing framework with\n",
        "    language-integrated APIs in Scala, Java, Python and R. As a rapidly evolving open source project, with an increasing number of contributors from\n",
        "    both academia and industry, it is difficult for researchers to comprehend the full body of development and research behind Apache Spark,\n",
        "    especially those who are beginners in this area. In this paper, we present a technical review on big data analytics using Apache Spark.\n",
        "    This review focuses on the key components, abstractions and features of Apache Spark. More specifically, it shows what Apache Spark has for designing\n",
        "    and implementing big data algorithms and pipelines for machine learning, graph analysis and stream processing. In addition, we highlight some research\n",
        "    and development directions on Apache Spark for big data analytics.\"\"\",\n",
        "\n",
        "    \"\"\"Football should not be considered only a branch of sports. Football is a sociological phenomenon. Fans being together doesn't always make for a peaceful\n",
        "    atmosphere. Those who fail to control their aggressive tendencies create incidents that overshadow football. The purpose of this article is to determine\n",
        "    the emergence of aversive social learning in football fans. Football fans are evaluated within the framework of the social learning theory, which is\n",
        "    the basis of the aggressive theory. The article reveals the importance of learning by anticipating the behavior of aggressive others and by imitating\n",
        "    fan groups and group leaders as well as media personalities.\"\"\",\n",
        "\n",
        "    \"\"\"Plant foods are consumed worldwide due to their immense energy density and nutritive value. Their consumption has been following an increasing trend\n",
        "    due to several metabolic disorders linked to non-vegetarian diets. In addition to their nutritive value, plant foods contain several bioactive\n",
        "    constituents that have been shown to possess health-promoting properties. Plant-derived bioactive compounds, such as biologically active proteins,\n",
        "    polyphenols, phytosterols, biogenic amines, carotenoids, etc., have been reported to be beneficial for human health, for instance in cases of cancer,\n",
        "    cardiovascular diseases, and diabetes, as well as for people with gut, immune function, and neurodegenerative disorders. Previous studies have reported\n",
        "    that bioactive components possess antioxidative, anti-inflammatory, and immunomodulatory properties, in addition to improving intestinal barrier\n",
        "    functioning etc., which contribute to their ability to mitigate the pathological impact of various human diseases. This review describes the bioactive\n",
        "    components derived from fruit, vegetables, cereals, and other plant sources with health promoting attributes, and the mechanisms responsible for the\n",
        "    bioactive properties of some of these plant components. This review mainly compiles the potential of food derived bioactive compounds, providing\n",
        "    information for researchers that may be valuable for devising future strategies such as choosing promising bioactive ingredients to make functional foods\n",
        "    for various non-communicable disorders.\"\"\",\n",
        "\n",
        "    \"\"\"In this paper, a mathematical model with a standard incidence rate is proposed to assess the role of media such as facebook, television, radio and tweeter\n",
        "    in the mitigation of the outbreak of COVID-19. The basic reproduction number R0 which is the threshold dynamics parameter between the disappearance and\n",
        "    the persistence of the disease has been calculated. And, it is obvious to see that it varies directly to the number of hospitalized people, asymptomatic,\n",
        "    symptomatic carriers and the impact of media coverage. The local and the global stabilities of the model have also been investigated by using the\n",
        "    Routh‚ÄìHurwitz criterion and the Lyapunov‚Äôs functional technique, respectively. Furthermore, we have performed a local sensitivity analysis to assess the\n",
        "    impact of any variation in each one of the model parameter on the threshold R0 and the course of the disease accordingly. We have also computed the\n",
        "    approximative rate at which herd immunity will occur when any control measure is implemented. To finish, we have presented some numerical simulation\n",
        "    results by using some available data from the literature to corroborate our theoretical findings.\"\"\",\n",
        "\n",
        "    \"\"\"Online mapping technologies such as Google Maps and Street View have become increasingly accessible. These technologies have many convenient uses in\n",
        "    everyday life, but law enforcement agencies have expressed concern that they could be exploited by offenders and might alter existing offending patterns\n",
        "    and habits. For environmental criminologists, they have the potential to open up new approaches to conducting research. This paper draws on the results\n",
        "    of earlier studies in related fields and a handful of criminological studies to discuss how these online mapping applications can trigger new research\n",
        "    questions, and how they could be considered a valuable methodological addition to criminological research.\"\"\",\n",
        "\n",
        "    \"\"\"In recent years, extensive research has been dedicated to Mars exploration and the potential for sustainable interplanetary human colonization.\n",
        "    One of the significant challenges in ensuring the survival of life on Mars lies in the production of food as the Martian environment is highly inhospitable\n",
        "    to agriculture, rendering it impractical to transport food from Earth. To improve the well-being and quality of life for future space travelers on Mars,\n",
        "    it is crucial to develop innovative horticultural techniques and food processing technologies. The unique challenges posed by the Martian environment,\n",
        "    such as the lack of oxygen, nutrient-deficient soil, thin atmosphere, low gravity, and cold, dry climate, necessitate the development of advanced farming\n",
        "    strategies. This study explores existing knowledge and various technological innovations that can help overcome the constraints associated with food\n",
        "    production and water extraction on Mars. The key lies in utilizing resources available on Mars through in-situ resource utilization. Water can be\n",
        "    extracted from beneath the ice and from the Martian soil. Furthermore, hydroponics in controlled environment chambers, equipped with nutrient delivery\n",
        "    systems and waste recovery mechanisms, have been investigated as a means of cultivating crops on Mars. The inefficiency of livestock production, which\n",
        "    requires substantial amounts of water and land, highlights the need for alternative protein sources such as microbial protein, insects, and in-vitro meat.\n",
        "    Moreover, the fields of synthetic biology and 3-D food printing hold immense potential in revolutionizing food production and making significant\n",
        "    contributions to the sustainability of human life on Mars.\"\"\"\n",
        "]\n",
        "\n",
        "expected_keywords_list = [\n",
        "    [\n",
        "        \"Sentiment classification\", \"Text classification\", \"Natural language processing\",\n",
        "        \"Emotion detection\", \"Sentiment analysis\"\n",
        "    ],\n",
        "    [\n",
        "        \"Smart City\", \"Measurement\", \"Ranking\", \"Framework\", \"Model\", \"Planning\", \"Project\"\n",
        "    ],\n",
        "    [\n",
        "        \"Big data\", \"Data analysis\", \"Distributed and parallel computing\", \"Cluster computing\",\n",
        "        \"Apache Spark\", \"Machine learning\", \"Graph analysis\", \"Stream processing\",\n",
        "        \"Resilient Distributed Datasets\"\n",
        "    ],\n",
        "    [\n",
        "        \"Football\", \"Fans\", \"Aggression\", \"Fan behavior\", \"Social learning theory\"\n",
        "    ],\n",
        "    [\n",
        "        \"plant foods\", \"bioactive components\", \"antioxidants\", \"polyphenols\", \"anti-inflammatory\",\n",
        "        \"chronic diseases\", \"human health\", \"gut health\"\n",
        "    ],\n",
        "    [\n",
        "        \"COVID-19 mitigation\", \"Media coverage\", \"Mathematical study\", \"Sensitivity analysis\",\n",
        "        \"Herd immunity\", \"Numerical simulation\"\n",
        "    ],\n",
        "    [\n",
        "        \"Google Maps\", \"Street View\", \"Environmental criminology\", \"Innovation\", \"Methodology\", \"Methods\"\n",
        "    ],\n",
        "    [\n",
        "        \"Mars\", \"In-situ food production\", \"Single-cell proteins\", \"Insect farming\",\n",
        "        \"3-D food printing\", \"Synthetic biology\"\n",
        "    ]\n",
        "]\n",
        "\n",
        "results = process_abstracts(abstracts, expected_keywords_list)\n",
        "\n",
        "for i, res in enumerate(results):\n",
        "    print(f\"\\nüìÑ Abstract {i+1}\")\n",
        "    print(\"üéØ Keywords generated by Gemini:\", res[\"gemini_keywords\"])\n",
        "    print(\"üëÅÔ∏è Expected keywords were:\", res[\"expected_keywords\"])\n",
        "    print(f\"‚úÖ Matches found: {res['match_count']} of 5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
